# ðŸŽ“ edu-vision-action-detection  
*A PyTorchâ€“powered computer-vision model for detecting observable classroom actions*

---

## ðŸ“Œ Overview

This repository contains a modular deep-learning pipeline that detects **observable student actions** from classroom images â€” such as:

- âœï¸ writing
- ðŸ§‘â€ðŸ« looking at board / attention-direction
- âœ‹ hand raised
- ðŸ“± device visible (phone / laptop)

**No mental-state prediction** is performed â€” only **objective, physically observable actions.**

The project is part of a long-term roadmap toward building data-driven educational tools and **will later integrate as a micro-service** into a larger â€œTeacher Assistant Dashboardâ€ ecosystem.

---

## ðŸš€ What This Repo Demonstrates (Portfolio Highlights)

| Skill Area | Evidence |
|------------|----------|
| Deep Learning | ResNet-based classifier, PyTorch training pipeline |
| Computer Vision | ImageFolder dataset, transforms, augmentation |
| Engineering Maturity | Modular repo, separation of model vs. UI, scalable architecture |
| Deployment-readiness | Streamlit inference UI planned, save/load model weights |

If you're reviewing this repo as a hiring manager:
> This project showcases end-to-end ML capability: data â†’ model â†’ training â†’ deployment.

---

## ðŸ§  Project Architecture

